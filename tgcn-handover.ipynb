{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv, ChebConv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "dataset_path = 'simulator_data_1.csv'\n",
    "# dataset_path = '/content/simulator_data.csv'\n",
    "# df = pd.read_csv(dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# dataset_path = \"path_to_your_dataset.csv\"  # Replace with your actual dataset path\n",
    "data = pd.read_csv(dataset_path)\n",
    "\n",
    "# Function to compute the distance between two points\n",
    "def calculate_distance(x1, y1, x2, y2):\n",
    "    return np.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check for handovers between timestamps\n",
    "def check_handovers(df, current_timestamp, next_timestamp):\n",
    "    current_data = df[df['timestamp'] == current_timestamp]\n",
    "    next_data = df[df['timestamp'] == next_timestamp]\n",
    "\n",
    "    handovers = {}\n",
    "    for vid in current_data['vehicleId'].unique():\n",
    "        current_master = current_data[current_data['vehicleId'] == vid]['masterId'].iloc[0]\n",
    "        next_master = next_data[next_data['vehicleId'] == vid]['masterId'].iloc[0] if vid in next_data['vehicleId'].values else current_master\n",
    "        handovers[vid] = current_master != next_master\n",
    "\n",
    "    return handovers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a graph data object and NetworkX graph for a given timestamp\n",
    "def create_graph_data_for_timestamp(df, timestamp):\n",
    "    timestamp_data = df[df['timestamp'] == timestamp]\n",
    "    vehicle_ids = timestamp_data['vehicleId'].unique()\n",
    "    print('number of vehicles:', vehicle_ids.size)\n",
    "    tower_ids = timestamp_data['towerId'].unique()\n",
    "    print('number of towers:', tower_ids.size)\n",
    "    vehicle_mapping = {vid: i for i, vid in enumerate(vehicle_ids)}\n",
    "    tower_mapping = {tid: i + len(vehicle_ids) for i, tid in enumerate(tower_ids)}\n",
    "\n",
    "    node_features = []\n",
    "    edge_index = []\n",
    "    edge_features = []\n",
    "\n",
    "    G = nx.Graph()  # NetworkX Graph for visualization\n",
    "\n",
    "    # Process vehicle nodes\n",
    "    for vid in vehicle_ids:\n",
    "        try:\n",
    "            vehicle_data = timestamp_data[timestamp_data['vehicleId'] == vid].iloc[2]\n",
    "        except IndexError:\n",
    "            try:\n",
    "                vehicle_data = timestamp_data[timestamp_data['vehicleId'] == vid].iloc[1]\n",
    "            except IndexError:\n",
    "                vehicle_data = timestamp_data[timestamp_data['vehicleId'] == vid].iloc[0]\n",
    "        vehicle_data = timestamp_data[timestamp_data['vehicleId'] == vid].iloc[0]\n",
    "        vehicle_features = [\n",
    "            vehicle_data['vehicleSpeed'], vehicle_data['vehicleDirection'], vehicle_data['vehiclePosX'],\n",
    "            vehicle_data['vehiclePosY']\n",
    "        ]\n",
    "        node_features.append(vehicle_features)\n",
    "        G.add_node(vehicle_mapping[vid], speed=vehicle_data['vehicleSpeed'], dir=vehicle_data['vehicleDirection'], \n",
    "                  pos=(vehicle_data['vehiclePosX'], vehicle_data['vehiclePosY']),\n",
    "                   type='vehicle', label=f'{vid}')\n",
    "\n",
    "    # Process tower nodes\n",
    "    for tid in tower_ids:\n",
    "        master_data = timestamp_data[timestamp_data['masterId'] == tid][::-1]\n",
    "        if not master_data.empty:\n",
    "            tower_data = master_data.iloc[0]\n",
    "            tower_features = [\n",
    "                tower_data['masterPosX'], tower_data['masterPosY'],\n",
    "                tower_data['masterLoad'], 0.0  # Placeholder values for missing features\n",
    "            ]\n",
    "            G.add_node(tower_mapping[tid], pos=(tower_data['masterPosX'], tower_data['masterPosY']), load=tower_data['masterLoad'],\n",
    "                    type='tower', label=f'T{tid}')\n",
    "        else:\n",
    "            tower_data = timestamp_data[timestamp_data['towerId'] == tid][::-1].iloc[0]\n",
    "            tower_features = [\n",
    "                tower_data['towerPosX'], tower_data['towerPosY'],\n",
    "                tower_data['towerLoad'], 0.0  # Placeholder values for missing features\n",
    "            ]\n",
    "            G.add_node(tower_mapping[tid], pos=(tower_data['towerPosX'], tower_data['towerPosY']), load=tower_data['towerLoad'],\n",
    "                        type='tower', label=f'T{tid}')\n",
    "\n",
    "        node_features.append(tower_features)\n",
    "        \n",
    "\n",
    "    # Add edges based on the masterId\n",
    "    for _, row in timestamp_data.iterrows():\n",
    "        vehicle_id = vehicle_mapping[row['vehicleId']]\n",
    "        tower_id = tower_mapping[row['masterId']]  # Connect to the master tower\n",
    "        edge_index.append([vehicle_id, tower_id])\n",
    "        \n",
    "\n",
    "        distance = calculate_distance(row['vehiclePosX'], row['vehiclePosY'],\n",
    "                                      row['masterPosX'], row['masterPosY'])\n",
    "        edge_features.append([row['throughput'], row['masterRssi'], distance])\n",
    "\n",
    "        # Add edges to the NetworkX graph\n",
    "        G.add_edge(vehicle_id, tower_id, throughput=row['throughput'],  rssi=row['masterRssi'], distance=distance)\n",
    "    \n",
    "    node_features_tensor = torch.tensor(node_features, dtype=torch.float)\n",
    "    edge_index_tensor = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    # print(edge_index_tensor)\n",
    "    # print(len(edge_index))\n",
    "    edge_features_tensor = torch.tensor(edge_features, dtype=torch.float)\n",
    "\n",
    "    graph_data = Data(x=node_features_tensor, edge_index=edge_index_tensor, edge_attr=edge_features_tensor)\n",
    "    print(\"node features: \", graph_data.x.shape,\"edge index: \", graph_data.edge_index.shape,\"edge attr: \", graph_data.edge_attr.shape)\n",
    "    return graph_data, G, vehicle_mapping, tower_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "[0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0, 6.5, 7.0, 7.5, 8.0, 8.5, 9.0, 9.5, 10.0, 10.5]\n",
      "0\n",
      "0\n",
      "number of vehicles: 31\n",
      "number of towers: 10\n",
      "node features:  torch.Size([41, 4]) edge index:  torch.Size([2, 54]) edge attr:  torch.Size([54, 3])\n",
      "1\n",
      "number of vehicles: 81\n",
      "number of towers: 10\n",
      "node features:  torch.Size([91, 4]) edge index:  torch.Size([2, 146]) edge attr:  torch.Size([146, 3])\n",
      "2\n",
      "number of vehicles: 99\n",
      "number of towers: 10\n",
      "node features:  torch.Size([109, 4]) edge index:  torch.Size([2, 182]) edge attr:  torch.Size([182, 3])\n",
      "3\n",
      "number of vehicles: 99\n",
      "number of towers: 10\n",
      "node features:  torch.Size([109, 4]) edge index:  torch.Size([2, 182]) edge attr:  torch.Size([182, 3])\n",
      "4\n",
      "number of vehicles: 99\n",
      "number of towers: 10\n",
      "node features:  torch.Size([109, 4]) edge index:  torch.Size([2, 182]) edge attr:  torch.Size([182, 3])\n",
      "5\n",
      "number of vehicles: 99\n",
      "number of towers: 10\n",
      "node features:  torch.Size([109, 4]) edge index:  torch.Size([2, 182]) edge attr:  torch.Size([182, 3])\n",
      "6\n",
      "number of vehicles: 99\n",
      "number of towers: 10\n",
      "node features:  torch.Size([109, 4]) edge index:  torch.Size([2, 182]) edge attr:  torch.Size([182, 3])\n",
      "7\n",
      "number of vehicles: 99\n",
      "number of towers: 10\n",
      "node features:  torch.Size([109, 4]) edge index:  torch.Size([2, 182]) edge attr:  torch.Size([182, 3])\n",
      "8\n",
      "number of vehicles: 100\n",
      "number of towers: 10\n",
      "node features:  torch.Size([110, 4]) edge index:  torch.Size([2, 184]) edge attr:  torch.Size([184, 3])\n",
      "9\n",
      "number of vehicles: 100\n",
      "number of towers: 10\n",
      "node features:  torch.Size([110, 4]) edge index:  torch.Size([2, 185]) edge attr:  torch.Size([185, 3])\n",
      "10\n",
      "number of vehicles: 100\n",
      "number of towers: 10\n",
      "node features:  torch.Size([110, 4]) edge index:  torch.Size([2, 186]) edge attr:  torch.Size([186, 3])\n",
      "11\n",
      "number of vehicles: 100\n",
      "number of towers: 10\n",
      "node features:  torch.Size([110, 4]) edge index:  torch.Size([2, 185]) edge attr:  torch.Size([185, 3])\n",
      "12\n",
      "number of vehicles: 100\n",
      "number of towers: 10\n",
      "node features:  torch.Size([110, 4]) edge index:  torch.Size([2, 183]) edge attr:  torch.Size([183, 3])\n",
      "13\n",
      "number of vehicles: 100\n",
      "number of towers: 10\n",
      "node features:  torch.Size([110, 4]) edge index:  torch.Size([2, 183]) edge attr:  torch.Size([183, 3])\n",
      "14\n",
      "number of vehicles: 100\n",
      "number of towers: 10\n",
      "node features:  torch.Size([110, 4]) edge index:  torch.Size([2, 183]) edge attr:  torch.Size([183, 3])\n",
      "15\n",
      "number of vehicles: 100\n",
      "number of towers: 10\n",
      "node features:  torch.Size([110, 4]) edge index:  torch.Size([2, 183]) edge attr:  torch.Size([183, 3])\n",
      "16\n",
      "number of vehicles: 100\n",
      "number of towers: 10\n",
      "node features:  torch.Size([110, 4]) edge index:  torch.Size([2, 184]) edge attr:  torch.Size([184, 3])\n",
      "17\n",
      "number of vehicles: 100\n",
      "number of towers: 10\n",
      "node features:  torch.Size([110, 4]) edge index:  torch.Size([2, 184]) edge attr:  torch.Size([184, 3])\n",
      "18\n",
      "number of vehicles: 100\n",
      "number of towers: 10\n",
      "node features:  torch.Size([110, 4]) edge index:  torch.Size([2, 183]) edge attr:  torch.Size([183, 3])\n",
      "19\n",
      "number of vehicles: 100\n",
      "number of towers: 10\n",
      "node features:  torch.Size([110, 4]) edge index:  torch.Size([2, 182]) edge attr:  torch.Size([182, 3])\n"
     ]
    }
   ],
   "source": [
    "def generate_sequences(df, sequence_length):\n",
    "    \"\"\"\n",
    "    Generate sequences of graph data objects for the given sequence length.\n",
    "    Each sequence consists of consecutive timestamps data.\n",
    "    \"\"\"\n",
    "    timestamps = sorted(df['timestamp'].unique())\n",
    "    print(len(timestamps))\n",
    "    print(timestamps)\n",
    "    \n",
    "    sequences = []\n",
    "# 202 - 20 = 182  0+0 =0   0+1 = 1  ... 0 + 20 = 20 / 182*20\n",
    "# 21 - 20 = 1\n",
    "\n",
    "#0+0 / 0+1 / 0+2 / ... / 0+19 [0,19]\n",
    "#1+0 / 1+1 / 1+2 / ... / 1+19 [1,20]\n",
    "    for i in range(len(timestamps) - sequence_length):\n",
    "        print(i)\n",
    "        sequence_graphs = []\n",
    "        for j in range(sequence_length):\n",
    "            print(j)\n",
    "            timestamp = timestamps[i + j]\n",
    "            graph_data, _, _, _ = create_graph_data_for_timestamp(df, timestamp)\n",
    "            sequence_graphs.append(graph_data)\n",
    "        sequences.append(sequence_graphs)\n",
    "\n",
    "    return sequences\n",
    "\n",
    "# Generate sequences\n",
    "sequences = generate_sequences(data,20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Data(x=[41, 4], edge_index=[2, 54], edge_attr=[54, 3]), Data(x=[91, 4], edge_index=[2, 146], edge_attr=[146, 3]), Data(x=[109, 4], edge_index=[2, 182], edge_attr=[182, 3]), Data(x=[109, 4], edge_index=[2, 182], edge_attr=[182, 3]), Data(x=[109, 4], edge_index=[2, 182], edge_attr=[182, 3]), Data(x=[109, 4], edge_index=[2, 182], edge_attr=[182, 3]), Data(x=[109, 4], edge_index=[2, 182], edge_attr=[182, 3]), Data(x=[109, 4], edge_index=[2, 182], edge_attr=[182, 3]), Data(x=[110, 4], edge_index=[2, 184], edge_attr=[184, 3]), Data(x=[110, 4], edge_index=[2, 185], edge_attr=[185, 3]), Data(x=[110, 4], edge_index=[2, 186], edge_attr=[186, 3]), Data(x=[110, 4], edge_index=[2, 185], edge_attr=[185, 3]), Data(x=[110, 4], edge_index=[2, 183], edge_attr=[183, 3]), Data(x=[110, 4], edge_index=[2, 183], edge_attr=[183, 3]), Data(x=[110, 4], edge_index=[2, 183], edge_attr=[183, 3]), Data(x=[110, 4], edge_index=[2, 183], edge_attr=[183, 3]), Data(x=[110, 4], edge_index=[2, 184], edge_attr=[184, 3]), Data(x=[110, 4], edge_index=[2, 184], edge_attr=[184, 3]), Data(x=[110, 4], edge_index=[2, 183], edge_attr=[183, 3]), Data(x=[110, 4], edge_index=[2, 182], edge_attr=[182, 3])]]\n"
     ]
    }
   ],
   "source": [
    "print(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TGCNUnsupervised(nn.Module):\n",
    "    def __init__(self, node_feature_size, edge_feature_size, hidden_size):\n",
    "        super(TGCNUnsupervised, self).__init__()\n",
    "        self.conv1 = GCNConv(node_feature_size, hidden_size)\n",
    "        self.conv2 = GCNConv(hidden_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size , hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, edge_feature_size)  # Predicting future edge features\n",
    "\n",
    "    def forward(self, data_list):\n",
    "        x_all, edge_index_all, edge_attr_all = [], [], []\n",
    "        max_num_nodes = max(data.x.size(0) for data in data_list)\n",
    "        for data in data_list:\n",
    "            x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "            num_nodes = x.size(0)\n",
    "            padding_size = max_num_nodes - num_nodes\n",
    "            padding = torch.zeros(padding_size, x.size(1)).to(x.device)\n",
    "            x = torch.cat([x, padding], dim=0)\n",
    "            x = F.relu(self.conv1(x, edge_index))\n",
    "            x = F.relu(self.conv2(x, edge_index))\n",
    "            x_all.append(x)\n",
    "            edge_index_all.append(edge_index)\n",
    "            edge_attr_all.append(edge_attr)\n",
    "        x_all = torch.stack(x_all)\n",
    "        out, _ = self.gru(x_all)\n",
    "        pred_edge_attr = self.fc(out)\n",
    "        return pred_edge_attr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TGCNUnsupervised(4, 3, hidden_size=64)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_unsupervised(model, data_sequences, optimizer):\n",
    "    model.train()\n",
    "    for sequence in data_sequences:  # Each contains graphs for 20 timestamps + 1 for target\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Assuming your model outputs predictions for the sequence\n",
    "        pred_edge_attr_seq = model(sequence[:-1])  # Model processes all but the last graph for prediction\n",
    "\n",
    "        # The target sequence's edge attributes\n",
    "        actual_edge_attr = sequence[-1].edge_attr\n",
    "\n",
    "        # Assuming pred_edge_attr_seq[-1] and actual_edge_attr are tensors\n",
    "        min_edges = min(pred_edge_attr_seq[-1].size(0), actual_edge_attr.size(0))\n",
    "\n",
    "        # Compute loss only over the common set of edges\n",
    "        loss = F.mse_loss(pred_edge_attr_seq[-1][:min_edges], actual_edge_attr[:min_edges])\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"Training Completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Completed\n"
     ]
    }
   ],
   "source": [
    "# train_unsupervised(model, sequences, optimizer)\n",
    "train_unsupervised(model, sequences, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_handover_targets(model, current_sequence):\n",
    "    \"\"\"\n",
    "    Infer handover targets for each vehicle in the sequence.\n",
    "\n",
    "    :param model: Trained TGCN model.\n",
    "    :param current_sequence: Sequence of graph data leading up to the current timestamp.\n",
    "    :return: Dict mapping vehicle IDs to their recommended handover tower IDs.\n",
    "    \"\"\"\n",
    "    pred_edge_attr = model(current_sequence)[-1]  # Get predictions for the next timestamp\n",
    "    handover_decisions = {}\n",
    "\n",
    "    for i, edge in enumerate(current_sequence[-1].edge_index.t()):\n",
    "        vehicle_id, tower_id = edge.tolist()\n",
    "        # Assuming edge attributes include predicted signal quality and distance\n",
    "        predicted_signal_quality, predicted_distance = pred_edge_attr[i]\n",
    "\n",
    "        # Calculate score (example calculation, adjust according to your needs)\n",
    "        score = predicted_signal_quality - predicted_distance\n",
    "\n",
    "        if vehicle_id not in handover_decisions or handover_decisions[vehicle_id]['score'] < score:\n",
    "            handover_decisions[vehicle_id] = {'tower_id': tower_id, 'score': score}\n",
    "\n",
    "    # Select the tower with the highest score for each vehicle\n",
    "    recommended_handovers = {v: d['tower_id'] for v, d in handover_decisions.items()}\n",
    "    return recommended_handovers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
